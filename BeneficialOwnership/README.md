# Steps to Run the Beneficial Ownership Engine

1. Make sure all the tables you need are in the curated zone, under a single subfolder, in .csv format. These tables are generated by ingestion of the open source datasets to the raw zone, then triggering Consumer Synapse pipeline 'PL_BO_Part1_FlattenAndValidate', which will store the required Benedifical Ownership Engine data in the Beneficial Ownership Model in the Consumer Synapse, and save the required csv files. The Beneficial Ownership Model are includes Activity, Contact, Ownership, AttributeDefinition, RedFlagDefinition , and EntityWeight tables and is provided so that these data can be queried. The Beneficial Ownership Engine requires the csv files as inputs.
2. Make sure the .whl and .env file are installed on the Spark cluster that will be used to run the Beneficial Ownership notebook
3. In the notebook, update the variables of folderpath, storagename, and datecountry:
    - **folderpath** needs to match the subfolder name in the curated zone where the .csv are placed, 
    - **storagename** is the storage account name, and 
    - **datecountry** is the name of the lake database where the final reports will be generated, as specified by the user. If datecountry is not changed, the dataw ll be overwritten in the subsequent run.

NOTE: For the sample Dominican Republic data, trigger Synapse pipleine the executed notebook 'NB_Run_Transparency_Engine_DR.ipynb'. The activity file for this dataset contains 'item' and 'tenderer information', not any 'buyer' or 'lot', so its config file was modified from the original NB_Run_Transparency_Engine.ipynb script.

The final results will be displayed into the synapse lake database and the final pbi report will need to be pointed to this in order to display the final results.

## Steps to Deploy the Beneficial Ownership PowerBI Report

1. Make sure your Beneficial Ownership Consumer is up and running.

2. [Create a Service Principal](https://learn.microsoft.com/en-us/azure/active-directory/develop/howto-create-service-principal-portal)

3. [Enable Service Principals in your Fabric Workspace as a Fabric Admin](https://learn.microsoft.com/en-us/power-bi/enterprise/service-premium-service-principal#enable-service-principals)

4. [Enable Access for the Service Prinicpal on your specified workspace](https://learn.microsoft.com/en-us/power-bi/enterprise/service-premium-service-principal#workspace-access)

5. Update the [dev variable file](variables/dev.json) with these following variables:
    - `'FabricWorkspaceID'`: The Fabric workspace you want to deploy the PBI Report to.
    - `'BeneficalOwnershipGeneratedDataLake'`: The name of the Synapse Datalake which was generated from running the Benificial Ownership consumer.

6. [Add the following Repository Secrets](https://docs.github.com/en/actions/security-guides/encrypted-secrets#creating-encrypted-secrets-for-a-repository) *with the same name*
    - **DEV_FABRIC_SPN_CLIENT_ID** (From Step 1) - [how to find](https://learn.microsoft.com/en-us/azure/active-directory/develop/app-objects-and-service-principals#application-object)
    - **DEV_FABRIC_SPN_SECRET** (From Step 1) - [secret value](https://learn.microsoft.com/en-us/azure/active-directory/develop/howto-create-service-principal-portal#option-2-create-a-new-application-secret)
    - **DEV_FABRIC_TENANT_ID** - [how to find](https://learn.microsoft.com/en-us/azure/active-directory/fundamentals/active-directory-how-to-find-tenant#find-tenant-id-through-the-azure-portal)

7. Trigger the **Consumer-PowerBI-Deployment** GitHub Action. If you're unfamiliar with triggering a GitHub Action, follow these [instructions](https://docs.github.com/en/actions/managing-workflow-runs/manually-running-a-workflow).
    - Input **dev** for the "Environment" input
    - Input **beneficial_ownership** for the "Consumer Folder Name" input
